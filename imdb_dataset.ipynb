{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0D0pFPe4Wg1",
        "colab_type": "text"
      },
      "source": [
        "# Importing the needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAPS3FK0xT6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87f4a746-5ad5-4850-c876-81a5e34c2db2"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import TensorBoard  \n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSOeodpO4weI",
        "colab_type": "text"
      },
      "source": [
        "# Loading the preloaded dataset from keras.datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZqAwcPKx_S2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Loading the Preloaded Data'''\n",
        "\n",
        "# call load_data with allow_pickle implicitly set to true\n",
        "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA_lGCS6x1Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Concatenating the data and targets\n",
        "data = np.concatenate((training_data, testing_data), axis=0)\n",
        "targets = np.concatenate((training_targets, testing_targets), axis=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0pr3RsZ4_yC",
        "colab_type": "text"
      },
      "source": [
        "Vectorising the data and coverting list objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU959vr5yzaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vectorising\n",
        "def vectorize(sequences, dimension = 10000):\n",
        " results = np.zeros((len(sequences), dimension))\n",
        " for i, sequence in enumerate(sequences):\n",
        "  results[i, sequence] = 1\n",
        " return results\n",
        "\n",
        "#Calling the vectorise function\n",
        "data = vectorize(data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuu8tgmM5L2h",
        "colab_type": "text"
      },
      "source": [
        "Splitting the data into Training and Testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oCu3TH9y8NC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "targets = np.array(targets).astype(\"float32\")\n",
        "X_test = data[:10000]\n",
        "y_test = targets[:10000]\n",
        "X_train = data[10000:]\n",
        "y_train = targets[10000:]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyEmqHNGy-h4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "55a3bc24-f5d2-42d5-b4d5-769165e22740"
      },
      "source": [
        "''' Analysinig the data set and reallocating'''\n",
        "print(X_train.shape)\n",
        "print(X_train)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 10000)\n",
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]]\n",
            "(10000, 10000)\n",
            "(40000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwdJQOhx5VwI",
        "colab_type": "text"
      },
      "source": [
        "# Constructing the deep neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYonNMitzEca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "09b77643-1a8b-4324-8ac4-96c6e27af854"
      },
      "source": [
        "\n",
        "model =Sequential()\n",
        "# Input - Layer\n",
        "model.add(Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
        "# Hidden - Layers\n",
        "model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
        "model.add(Dense(50, activation = \"relu\"))\n",
        "model.add(Dropout(0.2, noise_shape=None, seed=None))\n",
        "model.add(Dense(50, activation = \"relu\"))\n",
        "# Output- Layer\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "#Fitting the model \n",
        "fitted_model = model.fit(X_train, y_train, epochs = 2, batch_size =500, validation_data = (X_test,y_test))\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 50)                500050    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 505,201\n",
            "Trainable params: 505,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.4059 - accuracy: 0.8207 - val_loss: 0.2626 - val_accuracy: 0.8965\n",
            "Epoch 2/2\n",
            "80/80 [==============================] - 3s 40ms/step - loss: 0.2182 - accuracy: 0.9154 - val_loss: 0.2639 - val_accuracy: 0.8944\n",
            "Test-Accuracy: 0.8954499959945679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RADDPJh56JYL",
        "colab_type": "text"
      },
      "source": [
        "# Calculating the validation accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ0B5LTc6QCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "185cad72-7594-4074-bdec-6de76aa6be8a"
      },
      "source": [
        "print(\"Test-Accuracy:\", np.mean(fitted_model.history[\"val_accuracy\"]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test-Accuracy: 0.8954499959945679\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}